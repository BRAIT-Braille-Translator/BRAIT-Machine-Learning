{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c696d2e-b12e-4700-8cbc-4ca835abfa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781bc0cf-4147-4911-b480-4bc0e7099ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class BRAIT_CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(BRAIT_CNN, self).__init__()\n",
    "    self.brait1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.Dropout(p=0.01))\n",
    "    self.brait2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.Dropout(p=0.01))\n",
    "    self.brait3 = nn.Sequential(\n",
    "        nn.Linear(32*7*7, 100),\n",
    "        nn.Linear(100, 26))\n",
    "\n",
    "  def forward(self, x):\n",
    "    y = F.relu(self.brait1(x))\n",
    "    y = F.relu(self.brait2(y))\n",
    "\n",
    "    #flatten\n",
    "    y = y.view(-1, 32*7*7)\n",
    "    y = F.relu(self.brait3(y))\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3e03db6-a1d9-46fd-aba7-07bc4ca6b782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "31.0\n",
      "['f', 'a', 'm', 'i', 'l', 'y']\n",
      "4\n",
      "31.5\n",
      "['h', 'r', 'm', 'e']\n",
      "7\n",
      "76.28571428571429\n",
      "['p', 'r', 'a', 'i', 'r', 'i', 'e']\n",
      "14\n",
      "32.07142857142857\n",
      "['t', 'h', 'r', 'e', 'w', 'k', 't', 'a', 'e', 'j', 'a', 'a', 'l', 'l']\n",
      "2\n",
      "521.5\n",
      "['f', 'd']\n",
      "5\n",
      "30.8\n",
      "['w', 'o', 'u', 'l', 'd']\n",
      "15\n",
      "31.6\n",
      "['w', 'i', 't', 'h', 'k', 'h', 'i', 's', 't', 'f', 'a', 'm', 'i', 'l', 'y']\n",
      "10\n",
      "31.2\n",
      "['t', 'h', 'e', 'k', 'l', 'i', 't', 't', 'l', 'd']\n",
      "11\n",
      "32.18181818181818\n",
      "['l', 'i', 't', 't', 'l', 'e', 'e', 'g', 'i', 'a', 'l']\n",
      "3\n",
      "41.666666666666664\n",
      "['y', 'i', 'v']\n",
      "7\n",
      "67.57142857142857\n",
      "['s', 'c', 'w', 'c', 'a', 'z', 'z']\n",
      "1\n",
      "386.0\n",
      "['p']\n"
     ]
    }
   ],
   "source": [
    "def BRAIT_PREDICTION(img_path):\n",
    "    #load model BRAIT_CNN\n",
    "    model = BRAIT_CNN()\n",
    "    model.load_state_dict(torch.load('D:\\\\BRAIT-ML\\\\BRAIT-WEIGHT\\\\BRAIT_PYTORCH.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "    #prepocess image inputan convert jadi RGB\n",
    "    image = Image.open(img_path)\n",
    "    image = image.convert('RGB')\n",
    "\n",
    "    #segmentasi image inputan\n",
    "    width, height = image.size #mengambil ukuran size image\n",
    "    jumlah_segment = round(width/height/0.78) #menentukan jumlah segment huruf braille\n",
    "    print(jumlah_segment)\n",
    "    segment = width/jumlah_segment\n",
    "    print(segment)\n",
    "    \n",
    "    tamp=[]\n",
    "    for i in range (0,jumlah_segment):\n",
    "        cropped = image.crop((i*segment,0,(i+1)*segment,height))\n",
    "        cropped = np.array(cropped)\n",
    "        cropped = cv2.resize(cropped, (28, 28))\n",
    "        cropped = cropped.astype(np.float32) / 255.0\n",
    "        cropped = torch.from_numpy(cropped[None, :, :, :])\n",
    "        cropped = cropped.permute(0, 3, 1, 2)\n",
    "        predicted_tensor = model(cropped)\n",
    "        _, predicted_letter = torch.max(predicted_tensor, 1)\n",
    "        tamp.append(chr(97 + predicted_letter))     \n",
    "        \n",
    "    return tamp\n",
    "\n",
    "print(BRAIT_PREDICTION(r\"D:\\BRAIT-ML\\BRAIT-SAMPLE\\family.jpg\"))\n",
    "print(BRAIT_PREDICTION(r\"D:\\BRAIT-ML\\BRAIT-SAMPLE\\home.jpg\"))\n",
    "print(BRAIT_PREDICTION(r\"D:\\BRAIT-ML\\BRAIT-SAMPLE\\Prairie.jpg\"))\n",
    "print(BRAIT_PREDICTION(r\"D:\\BRAIT-ML\\BRAIT-SAMPLE\\threw_the_ball.png\"))\n",
    "print(BRAIT_PREDICTION(r\"D:\\BRAIT-ML\\BRAIT-SAMPLE\\sample2.jpg\"))\n",
    "print(BRAIT_PREDICTION(r\"D:\\BRAIT-ML\\BRAIT-SAMPLE\\would.png\"))\n",
    "print(BRAIT_PREDICTION(r\"D:\\BRAIT-ML\\BRAIT-SAMPLE\\with_his_family.png\"))\n",
    "print(BRAIT_PREDICTION(r\"D:\\BRAIT-ML\\BRAIT-SAMPLE\\the_little.png\"))\n",
    "print(BRAIT_PREDICTION(r\"D:\\BRAIT-ML\\BRAIT-SAMPLE\\little_girl.png\"))\n",
    "print(BRAIT_PREDICTION(r\"D:\\BRAIT-ML\\BRAIT-SAMPLE\\sample3.jpg\"))\n",
    "print(BRAIT_PREDICTION(r\"D:\\BRAIT-ML\\BRAIT-SAMPLE\\sample4.jpg\"))\n",
    "print(BRAIT_PREDICTION(r\"D:\\BRAIT-ML\\dataset-BRAIT\\dataset\\test\\i\\P_20180609_101612_2_2_1.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e723e6-82ca-4cf0-941d-7ccb67b03bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
